{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":330706,"sourceType":"datasetVersion","datasetId":140534}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SNN-ANN Model","metadata":{}},{"cell_type":"code","source":"! pip install snntorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision import utils as utls\n\nimport snntorch as snn\nfrom snntorch import utils\nfrom snntorch import surrogate\n\nimport numpy as np\nimport torch.optim as optim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\n\n# Load MNIST data\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n\n# Preprocess the data\ntrain_images = train_images.reshape((60000, 28 * 28))\ntrain_images = train_images.astype('float32') / 255\n\ntest_images = test_images.reshape((10000, 28 * 28))\ntest_images = test_images.astype('float32') / 255\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\n\n# Define a simple ANN model\nclass SimpleANN(tf.keras.Model):\n    def __init__(self):\n        super(SimpleANN, self).__init__()\n        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n\n    def call(self, inputs):\n        x = self.dense1(inputs)\n        return self.dense2(x)\n\n# Define a hypothetical SNN model (this is conceptual)\nclass SimpleSNN:\n    def process(self, inputs):\n        # Process inputs through SNN layers (hypothetical)\n        # In reality, this would involve a lot more complexity\n        return inputs  # For now, just returning the inputs\n\n# Combine SNN and ANN in a hybrid model\nclass HybridSNN_ANN(tf.keras.Model):\n    def __init__(self):\n        super(HybridSNN_ANN, self).__init__()\n        self.snn = SimpleSNN()\n        self.ann = SimpleANN()\n\n    def call(self, inputs):\n        snn_output = self.snn.process(inputs)\n        return self.ann(snn_output)\n\n# Instantiate and compile the model\nmodel = HybridSNN_ANN()\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_images, train_labels, epochs=5, batch_size=128)\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T17:41:45.960489Z","iopub.execute_input":"2023-12-31T17:41:45.961006Z","iopub.status.idle":"2023-12-31T17:42:25.747777Z","shell.execute_reply.started":"2023-12-31T17:41:45.96097Z","shell.execute_reply":"2023-12-31T17:42:25.746605Z"}}},{"cell_type":"code","source":"class HybridSNNANN(nn.Module):\n    def __init__(self, beta, thresh, latent_dim, num_steps):\n        super(HybridSNNANN, self).__init__()\n        self.num_steps = num_steps\n\n        # SNN Encoder\n        self.snn_encoder = nn.Sequential(\n            nn.Conv2d(1, 32, 3, padding=1, stride=2),\n            nn.BatchNorm2d(32),\n            snn.Leaky(beta=beta, threshold=thresh, init_hidden=True),\n            nn.Conv2d(32, 64, 3, padding=1, stride=2),\n            nn.BatchNorm2d(64),\n            snn.Leaky(beta=beta, threshold=thresh, init_hidden=True),\n            nn.Conv2d(64, 128, 3, padding=1, stride=2),\n            nn.BatchNorm2d(128),\n            snn.Leaky(beta=beta, threshold=thresh, init_hidden=True),\n            nn.Flatten(),\n            nn.Linear(128 * 4 * 4, latent_dim),\n            snn.Leaky(beta=beta, threshold=thresh, init_hidden=True, output=True)\n        )\n\n        # ANN Decoder\n        self.ann_decoder = nn.Sequential(\n            nn.Linear(latent_dim, 128 * 4 * 4),\n            nn.ReLU(),\n            nn.Unflatten(1, (128, 4, 4)),\n            nn.ConvTranspose2d(128, 64, 3, padding=1, stride=2, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 32, 3, padding=1, stride=2, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 1, 3, padding=1, stride=2, output_padding=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # Reset states\n        utils.reset(self.snn_encoder)\n        utils.reset(self.ann_decoder)\n\n        # Encode\n        spk_rec = []\n        mem_rec = []\n        for step in range(self.num_steps):\n            spk_x, mem_x = self.snn_encoder(x) # spikes, membrane potential\n            spk_rec.append(spk_x)\n            mem_rec.append(mem_x)\n        spk_rec = torch.stack(spk_rec, dim=2)\n        mem_rec = torch.stack(mem_rec, dim=2) \n            # combines a list of tensors representing membrane potentials at different time steps into a single tensor. \n            #It adds a new dimension at the third position (dim=2), effectively creating a 3D tensor \n\n        # Decode\n        decoded_x = []\n        for step in range(self.num_steps):\n            x_recon = self.ann_decoder(mem_rec[..., step]) #  2D slices of the 3D data at each iteration of the loop\n            decoded_x.append(x_recon)\n        decoded_x = torch.stack(decoded_x, dim=4)\n\n        out = decoded_x[:,:,:,:,-1]  # Taking the output at the last time step\n        return out\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, device, train_loader, optimizer, criterion, epoch):\n    model.train()\n    total_loss = 0.0\n\n    for batch_idx, (data, _) in enumerate(train_loader):  # Ignore original labels\n        data = data.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, data)  # Compare output with the input image\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    average_loss = total_loss / len(train_loader)\n    return average_loss\n\n# Validation function\ndef validate(model, device, val_loader, criterion):\n    model.eval()  # Set the model to evaluation mode\n    val_loss = 0.0\n\n    with torch.no_grad():  # Disable gradient calculation\n        for batch_idx, (data, _) in enumerate(val_loader):\n            data = data.to(device)\n            output = model(data)\n            loss = criterion(output, data)\n            val_loss += loss.item()\n\n    average_val_loss = val_loss / len(val_loader)\n    return average_val_loss\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:53:34.627090Z","iopub.execute_input":"2024-01-03T15:53:34.627440Z","iopub.status.idle":"2024-01-03T15:53:34.635617Z","shell.execute_reply.started":"2024-01-03T15:53:34.627415Z","shell.execute_reply":"2024-01-03T15:53:34.634696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# MNIST Dataset transformation\nfrom torch.utils.data import random_split\n\nbatch_size = 250\ninput_size = 32 #size of input to first convolutional layer\n\n# Load MNIST\ntrain_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Resize((input_size, input_size)),transforms.Normalize((0,), (1,))]), download=True)\n\n# Parameters\nvalidation_split = 0.2  # let's say you want to use 20% of the data for validation\nnum_train = len(train_dataset)\nnum_val = int(num_train * validation_split)\nnum_train = num_train - num_val\n\n# Split the dataset\ntrain_dataset, val_dataset = random_split(train_dataset, [num_train, num_val])\n\n# Create data loaders for training and validation sets\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) \n\ntest_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Resize((input_size, input_size)),transforms.Normalize((0,), (1,))]), download=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\n\n# Parameters and Run training and testing\n\n# Initialize the model\nbeta = 0.5\nthresh = 1.0\nlatent_dim = 256\nnum_steps = 10\nmodel = HybridSNNANN(beta, thresh, latent_dim, num_steps)\n\n\n\n#setup GPU\ndtype = torch.float\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\nmodel = model.to(device)\n\n# Define the optimizer and loss function\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.MSELoss()  # Assuming MSE loss, adjust as per your requirement\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:53:37.532215Z","iopub.execute_input":"2024-01-03T15:53:37.532557Z","iopub.status.idle":"2024-01-03T15:53:39.201093Z","shell.execute_reply.started":"2024-01-03T15:53:37.532533Z","shell.execute_reply":"2024-01-03T15:53:39.200308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\nprint(type(images))\nprint(images.shape)\nprint(labels.shape)\n#Printing the size of one image\nprint(images[1].numpy().squeeze().shape)\n\nplt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\n# Training loop    \ntrain_losses = []\nval_losses = []\nnum_epochs = 30\n# Early Stopping parameters\npatience = 3\nbest_val_loss = float('inf')\npatience_counter = 0\n\nstart_time = time.time()  # Record the start time of the training\n\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()  # Start time of the epoch\n\n    train_loss = train(model, device, train_loader, optimizer, criterion, epoch)\n    train_losses.append(train_loss)\n    # Training loop with early stopping\n    # Validation phase\n    val_loss = validate(model, device, val_loader, criterion)\n    val_losses.append(val_loss)\n    print(f'Epoch {epoch},Training Loss: {train_loss:.4f},Validation Loss: {val_loss:.4f}')\n\n    # Check for early stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n    \n    if patience_counter >= patience:\n        print(\"Early stopping triggered\")\n        break\n    \n\nend_time = time.time()  # Record the end time of the training\nprint(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:55:00.994164Z","iopub.execute_input":"2024-01-03T15:55:00.994877Z","iopub.status.idle":"2024-01-03T16:11:41.046837Z","shell.execute_reply.started":"2024-01-03T15:55:00.994844Z","shell.execute_reply":"2024-01-03T16:11:41.045809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.title('Loss Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:11:52.463863Z","iopub.execute_input":"2024-01-03T16:11:52.464228Z","iopub.status.idle":"2024-01-03T16:11:52.733016Z","shell.execute_reply.started":"2024-01-03T16:11:52.464200Z","shell.execute_reply":"2024-01-03T16:11:52.732124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the average loss for the entire test set\ntotal_loss = 0\n\nwith torch.no_grad():\n    for data, _ in test_loader:\n        data = data.to(device)\n        output = model(data)\n        loss = criterion(output, data)\n        total_loss += loss.item()\n\navg_loss = total_loss / len(test_loader)\nprint(f'Test set: Average loss: {avg_loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:12:06.043513Z","iopub.execute_input":"2024-01-03T16:12:06.044354Z","iopub.status.idle":"2024-01-03T16:12:10.186036Z","shell.execute_reply.started":"2024-01-03T16:12:06.044313Z","shell.execute_reply":"2024-01-03T16:12:10.185095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\n# Get some test data for visualization\ndataiter = iter(test_loader)\nimages, _ = next(dataiter)\nimages = images.to(device)\n\n# Get the output from the model for these images\nwith torch.no_grad():\n    model.eval()\n    outputs = model(images)\n\n# Convert images and outputs to CPU for plotting if running on GPU\nimages = images.cpu()\noutputs = outputs.cpu()\n\n# Plot the first few images and their reconstructions\nfig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 4))\nfor i in range(5):\n    # Display original images\n    ax = axes[0, i]\n    ax.imshow(images[i].squeeze(), cmap='Greys_r')\n    ax.set_title(f'Original {i+1}')\n    ax.axis('off')\n\n    # Display reconstructed images\n    ax = axes[1, i]\n    ax.imshow(outputs[i].squeeze(), cmap='Greys_r')\n    ax.set_title(f'Reconstructed {i+1}')\n    ax.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:12:31.942685Z","iopub.execute_input":"2024-01-03T16:12:31.943586Z","iopub.status.idle":"2024-01-03T16:12:32.825119Z","shell.execute_reply.started":"2024-01-03T16:12:31.943548Z","shell.execute_reply":"2024-01-03T16:12:32.824082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New modifications","metadata":{}},{"cell_type":"code","source":"! pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:33:06.166406Z","iopub.execute_input":"2024-01-03T16:33:06.167325Z","iopub.status.idle":"2024-01-03T16:33:18.146594Z","shell.execute_reply.started":"2024-01-03T16:33:06.167290Z","shell.execute_reply":"2024-01-03T16:33:18.145488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nmodel.to(device)  # Ensure the model is on the correct device\nsummary(model, input_size=(1, input_size, input_size))  # input_size should match the model's input\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:33:47.544712Z","iopub.execute_input":"2024-01-03T16:33:47.545271Z","iopub.status.idle":"2024-01-03T16:33:47.607683Z","shell.execute_reply.started":"2024-01-03T16:33:47.545227Z","shell.execute_reply":"2024-01-03T16:33:47.606691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Caltech101 dataset","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset\nimport os\n\ninput_size = 32  # size of input to first convolutional layer\n\n# Transformation for Caltech101 dataset\ntransform_caltech = transforms.Compose([\n    transforms.Resize((input_size, input_size)),\n    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale if needed\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))  # Adjust normalization for RGB images\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:34:40.863840Z","iopub.execute_input":"2024-01-03T16:34:40.864578Z","iopub.status.idle":"2024-01-03T16:34:40.870506Z","shell.execute_reply.started":"2024-01-03T16:34:40.864547Z","shell.execute_reply":"2024-01-03T16:34:40.869472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print all class names\nprint(caltech101_dataset.class_to_idx.keys())\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T16:35:04.856099Z","iopub.execute_input":"2024-01-03T16:35:04.857064Z","iopub.status.idle":"2024-01-03T16:35:04.894402Z","shell.execute_reply.started":"2024-01-03T16:35:04.857029Z","shell.execute_reply":"2024-01-03T16:35:04.893152Z"},"trusted":true},"execution_count":null,"outputs":[]}]}